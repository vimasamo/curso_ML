{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJERCICIO 3.1\n",
    "\n",
    "REGRESIÓN LINEAL (EJEMPLO SINTÉTICO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sintéticos para regresión lineal\n",
    "np.random.seed(42)\n",
    "X = 2.5 * np.random.randn(100, 1) + 1.5  # 100 muestras\n",
    "y = 1.7 * X.squeeze() + 0.8 + np.random.randn(100) * 2.0  # Relación aproximada\n",
    "\n",
    "# Convertir a DataFrame para visualizar\n",
    "df_reg = pd.DataFrame({\n",
    "    \"X\": X.squeeze(),\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Separar datos en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en test\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Métrica de evaluación\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Coeficiente beta_0 (intercept):\", lin_reg.intercept_)\n",
    "print(\"Coeficiente beta_1 (pendiente):\", lin_reg.coef_)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Visualización\n",
    "plt.scatter(X_test, y_test, label=\"Datos reales\")\n",
    "plt.plot(X_test, y_pred, color='red', label=\"Predicción\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Regresión Lineal (Datos Sintéticos)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJERCICIO 3.2\n",
    "\n",
    "CLASIFICACIÓN BINARIA CON REGRESIÓN LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos el dataset Iris pero lo simplificaremos a clasificación binaria\n",
    "# (ejemplo: Iris Versicolor vs. Iris Virginica).\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Filtramos para quedarnos solo con las clases 1 (versicolor) y 2 (virginica)\n",
    "# y con algunas variables para simplificar (ej. columnas 0 y 1: sepal length y sepal width)\n",
    "mask = (y != 0)  # tomamos solo las clases 1 y 2\n",
    "X_bin = X[mask, :2]  # primeras 2 características\n",
    "y_bin = y[mask]\n",
    "\n",
    "# Convertimos las clases 1 y 2 a 0 y 1 para usarlas en regresión logística\n",
    "y_bin = np.where(y_bin == 1, 0, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bin = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_bin)\n",
    "print(\"Accuracy en test:\", accuracy)\n",
    "\n",
    "# Curva ROC y AUC\n",
    "y_probas = log_reg.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probas)\n",
    "auc_value = roc_auc_score(y_test, y_probas)\n",
    "\n",
    "print(\"AUC:\", auc_value)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC = {auc_value:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC - Clasificación Binaria (Iris vs. Iris)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJERCICIO 3.3\n",
    "\n",
    "Validación Cruzada (Cross-Validation) para un modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con un dataset real (ejemplo: California Housing en sklearn).\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_housing = housing.data\n",
    "y_housing = housing.target\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_housing, y_housing, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"Scores MSE (negativo):\", scores)\n",
    "print(\"Scores RMSE:\", rmse_scores)\n",
    "print(\"RMSE promedio:\", rmse_scores.mean())\n",
    "print(\"Desviación estándar:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJERCICIO 3.4\n",
    "\n",
    "(Opcional) Intentar distintas métricas de evaluación en clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ej.: Precision, Recall, F1-score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Filtramos para quedarnos solo con las clases 1 (versicolor) y 2 (virginica)\n",
    "# y con algunas variables para simplificar (ej. columnas 0 y 1: sepal length y sepal width)\n",
    "mask = (y != 0)  # tomamos solo las clases 1 y 2\n",
    "X_bin = X[mask, :2]  # primeras 2 características\n",
    "y_bin = y[mask]\n",
    "\n",
    "# Convertimos las clases 1 y 2 a 0 y 1 para usarlas en regresión logística\n",
    "y_bin = np.where(y_bin == 1, 0, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bin = log_reg.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_bin)\n",
    "recall = recall_score(y_test, y_pred_bin)\n",
    "f1 = f1_score(y_test, y_pred_bin)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
